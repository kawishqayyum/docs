---
title: 网页抓取基础知识
description: 本文介绍了网页抓取中的基本概念，例如导航、解析、工作线程 (Worker) 类型和主要挑战
---

如果您对 JS 了如指掌，但同时又是网页数据抓取新手，那可能需要学习基本的抓取方法和一两种策略，以便成功抓取到数据。 

网页抓取的基本思路包含导航和解析两大步骤，而实现这两大步骤的策略则取决于所选择的技术方法，即是使用浏览器工作线程 (Browser worker) 还是 代码工作线程 (Code worker)。 

## 浏览器工作线程 vs. 代码工作线程

浏览器工作线程和代码工作线程是实现数据抓取的两大技术方法，您可根据自己的需求、预算以及抓取相关网站时面临的技术挑战，选择其中一种即可。

浏览器工作线程通过无头浏览器模拟用户与网站的交互， 

能够处理复杂的抓取任务，例如抓取用户输入的信息和动态内容加载。 使用浏览器工作线程运行代码需要更高的 CPM，但在某些使用场景中，它是获取数据的唯一可行解决方案。 

代码工作线程则在服务器端运行，通过 HTTP 请求执行抓取任务。 您只需通过脚本或程序向目标网站发送请求，即可从各个响应中提取数据，并将其保存至文件或数据库。 使用代码工作线程运行代码的成本更低、速度更快。

您可随时切换各种抓取工具的工作线程类型，因此无需执着于特定的工作线程，但请注意，一些函数（如 “wait” 函数）专为浏览器工作线程设计，只能与后者一起使用。进一步了解工作线程类型:  
https://docs.brightdata.com/scraping-automation/web-scraper-ide/worker-types

## 交互和解析

交互和解析是网页抓取过程的两大关键步骤，涉及访问和处理网站的 HTML 内容。

交互是指在网站各个页面或版块之间移动，找到所需数据的过程。此过程通常会涉及以下操作：向网站 URL 发送 GET 或 POST 请求，以及通过链接或提交表单的方式访问各个网页或版块。它还涉及点击、键入和等待等操作/命令。 一旦浏览器页面含有所需数据，抓取工具就会调用 `parse()` 函数获取数据（该步骤会触发解析器代码），然后调用 `collect()` 函数将数据记录添加至您的最终数据集。

例如：

```js
let data = parse();
collect({
    url: new URL(location.href),
    title: data.title,
    links: data.links,
});
```
解析是指从网站的 HTML 内容中提取相关数据的过程。 该过程涉及识别包含所需数据的 HTML 元素，以及使用正则表达式或其他方法从这些元素中提取数据的操作。 


例如：

```js
return {
  title: $('h1').text().trim(),
  links: $('a').toArray().map(e=>new URL($(e).attr('href'))),
};
```
例如，假设您想根据搜索词抓取电商网站的数据，并返回每种产品的信息（标题、描述、价格）。 
```js
let search_url = `https`:
navigate(search_url)
let max_page = parse().max_page
for (let i = 1; i <= max_page; i++)
{
    let search_page = new URL(search_url)
     if (i>1)
          search_page.searchParams.set('page', i)
     next_stage({search_page})
}
```

```js
navigate(input.search_page)
let listings = parse().listings
for (let listing_url of listings)
     next_stage({listing_url})
```

```scss
navigate(input.listing_url)
collect(parse())
```

1.  使用 GET 或 POST 请求导航至电商网站的搜索页面
2.  找到包含页数的 HTML 元素
3.  解析 HTML，提取搜索结果页数
4.  导航至每个结果页并执行以下操作 
5.  找到包含每个搜索结果数据的 HTML 元素
6.  解析每个搜索结果的 HTML 内容，收集每个产品页面的 URL
7.  导航至每个产品页面并执行以下操作
8.  找到包含所需产品数据的 HTML 元素
9.  解析 HTML，提取所需产品数据 

## 大规模抓取数据时面临的挑战和阻碍

小范围的数据抓取可能快速又简单，但如果您的项目需要采集大量的数据，则可能不得不应对一些挑战，因为一些网站会采取验证码、IP 封锁等技术来防止爬虫抓取数据。虽然您可以自己动手，想办法克服这些挑战，但整个过程可能会非常复杂、耗时。 为解决这一难题，我们在专有代理基础架构和网络解锁器的基础上构建了 IDE 云服务，让您无需自己动手即可解决相关挑战。